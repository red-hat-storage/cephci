#===============================================================================================
# Tier-level: 1
# Test-Suite: tier-1_rbd_mirror.yaml
# Test-Case: Configure RBD Mirror setup and run IOs
# Polarion ID : CEPH-83573329 - RBD HA MirroringDraft
#
# Cluster Configuration:
#    cephci/conf/nautilus/rbd/tier-1_rbd_mirror.yaml
#    No of Clusters : 2
#    Each cluster configuration
#    6-Node cluster(RHEL-8.3 and above)
#    1 MONS, 1 MDS, 1 MGR, 3 OSD and 1 RBD MIRROR service daemon(s)
#     Node1 - Mon, Mgr, Installer
#     Node2 - client
#     Node3 - OSD
#     Node4 - OSD,MDS
#     Node5 - OSD,MDS
#     Node6 - RBD Mirror

# The following evaluations are carried out
#   (1) Configures RBD Mirroring
#   (2) Creates Pool Image and enables Mirroring
#   (3) Runs IO using rbd bench
#===============================================================================================
tests:
  - test:
      name: pre-req
      module: install_prereq.py
      abort-on-fail: true
      desc: install ceph pre requisites

  - test:
      name: ceph ansible
      module: test_ansible.py
      clusters:
        ceph-rbd1:
          config:
            ansi_config:
              ceph_test: True
              ceph_origin: distro
              ceph_stable_release: nautilus
              ceph_repository: rhcs
              osd_scenario: lvm
              osd_auto_discovery: False
              journal_size: 1024
              ceph_stable: True
              ceph_stable_rh_storage: True
              fetch_directory: ~/fetch
              copy_admin_key: true
              dashboard_enabled: False
              ceph_conf_overrides:
                global:
                  osd_pool_default_pg_num: 64
                  osd_default_pool_size: 2
                  osd_pool_default_pgp_num: 64
                  mon_max_pg_per_osd: 1024
                mon:
                  mon_allow_pool_delete: true
              cephfs_pools:
                - name: "cephfs_data"
                  pgs: "8"
                - name: "cephfs_metadata"
                  pgs: "8"
        ceph-rbd2:
          config:
            ansi_config:
              ceph_test: True
              ceph_origin: distro
              ceph_stable_release: nautilus
              ceph_repository: rhcs
              osd_scenario: lvm
              osd_auto_discovery: False
              journal_size: 1024
              ceph_stable: True
              ceph_stable_rh_storage: True
              fetch_directory: ~/fetch
              copy_admin_key: true
              dashboard_enabled: False
              ceph_conf_overrides:
                global:
                  osd_pool_default_pg_num: 64
                  osd_default_pool_size: 2
                  osd_pool_default_pgp_num: 64
                  mon_max_pg_per_osd: 1024
                mon:
                  mon_allow_pool_delete: true
              cephfs_pools:
                - name: "cephfs_data"
                  pgs: "8"
                - name: "cephfs_metadata"
                  pgs: "8"
      desc: setup dual cluster using ceph-ansible
      destroy-cluster: false
      abort-on-fail: true

  - test:
      name: rbd mirror pre-req
      module: mirror_setup.py
      clusters:
        ceph-rbd1:
          config:
            way: two-way
      desc: pre-req for mirroring host
      abort-on-fail: true

  - test:
      name: test_rbd_mirror
      module: test_rbd_mirror.py
      clusters:
        ceph-rbd1:
          config:
            imagesize: 2G
            io-total: 200M
            resize_to: 5G
      polarion-id: CEPH-83573329
      desc: Create RBD mirrored image and run IOs

  - test:
      name: test_rbd_mirror_image
      module: test_rbd_mirror_image.py
      clusters:
        ceph-rbd1:
          config:
            imagesize: 2G
            io-total: 200M
      polarion-id: CEPH-83573329
      desc: Create RBD mirrored images in pool and run IOs
