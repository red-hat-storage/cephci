 tests:
   - test:
      name: pre-req
      module: install_prereq.py
      abort-on-fail: true
      desc: install ceph pre requisites

   - test:
      name: ceph ansible
      module: test_ansible.py
      clusters:
        ceph-rbd1:
          config:
            ansi_config:
              ceph_test: True
              ceph_origin: distro
              ceph_stable_release: nautilus 
              ceph_repository: rhcs
              osd_scenario: lvm
              osd_auto_discovery: False
              journal_size: 1024
              ceph_stable: True
              ceph_stable_rh_storage: True
              fetch_directory: ~/fetch
              copy_admin_key: true
              dashboard_enabled: False
              ceph_conf_overrides:
                global:
                  osd_pool_default_pg_num: 64
                  osd_default_pool_size: 2
                  osd_pool_default_pgp_num: 64
                  mon_max_pg_per_osd: 1024
                mon:
                  mon_allow_pool_delete: true
              cephfs_pools:
                - name: "cephfs_data"
                  pgs: "8"
                - name: "cephfs_metadata"
                  pgs: "8"
        ceph-rbd2:
          config:
            ansi_config:
              ceph_test: True
              ceph_origin: distro
              ceph_stable_release: nautilus
              ceph_repository: rhcs
              osd_scenario: lvm
              osd_auto_discovery: False
              journal_size: 1024
              ceph_stable: True
              ceph_stable_rh_storage: True
              fetch_directory: ~/fetch
              copy_admin_key: true
              dashboard_enabled: False
              ceph_conf_overrides:
                global:
                  osd_pool_default_pg_num: 64
                  osd_default_pool_size: 2
                  osd_pool_default_pgp_num: 64
                  mon_max_pg_per_osd: 1024
                mon:
                  mon_allow_pool_delete: true
              cephfs_pools:
                - name: "cephfs_data"
                  pgs: "8"
                - name: "cephfs_metadata"
                  pgs: "8"
      desc: setup dual cluster using ceph-ansible
      destroy-cluster: false
      abort-on-fail: true

   - test:
      name: rbd mirror pre-req
      module: mirror_setup.py
      clusters:
        ceph-rbd1:
          config:
            way: two-way
      desc: pre-req for mirroring host
      abort-on-fail: true

   - test:
      name: test_9470
      module: test_9470.py
      clusters:
        ceph-rbd1:
          config:
            imagesize: 2G
            io-total: 200M
      polarion-id: CEPH-9470
      desc: Recovery of abrupt failure of primary cluster

   - test:
      name: test_9471
      module: test_9471.py
      clusters:
        ceph-rbd1:
          config:
            imagesize: 2G
            io-total: 200M
      polarion-id: CEPH-9471
      desc: Recovery of shutdown primary cluster

   - test:
      name: test_9474
      module: test_9474.py
      clusters:
        ceph-rbd1:
          config:
            imagesize: 2G
            io-total: 200M
      polarion-id: CEPH-9474
      desc: Recovery of abrupt failure of secondary cluster

   - test:
      name: test_9475
      module: test_9475.py
      clusters:
        ceph-rbd1:
          config:
            imagesize: 2G
            io-total: 200M
      polarion-id: CEPH-9475
      desc: Recovery of shutdown secondary cluster

   - test:
      name: test_11489
      module: test_11489.py
      clusters:
        ceph-rbd1:
          config:
            imagesize: 2G
            io-total: 100M
            delay: 600
      polarion-id: CEPH-11489
      desc: Delayed replication
