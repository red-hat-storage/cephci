#===============================================================================================
# Tier-level: 1
# Test-Suite: tier1_upgrade_container.yaml
# Test-Case: Upgrade Containerized Ceph from CDN to latest ceph container image
#
# Cluster Configuration:
#    cephci/conf/nautilus/ansible/tier-1_upgrade.yaml
#
#    7-Node cluster(RHEL-7.9 and above)
#    3 MONS, 2 MDS, 1 MGR, 3 OSD and 2 RGW service daemon(s)
#     Node1 - Mon, Mgr, Installer, OSD
#     Node2 - Mon, Mgr, OSD
#     Node3 - Mon, OSD
#     Node4 - Client, Grafana
#     Node5 - OSD, RGW, MDS
#     Node6 - NFS, ISCSI
#     Node7 - RGW, ISCSI
#
# Test Steps:
#   (1) Install Pre-requisites, and Deploy Ceph using ceph-ansible with CDN/GA container image
#   (2) Run RBD IO.
#   (3) Upgrade Ceph cluster to latest container image.
#   (4) Run RGW IO.
#===============================================================================================
tests:
- test:
    name: install ceph pre-requisites
    module: install_prereq.py
    abort-on-fail: True

- test:
    name: ceph ansible install containerized rhcs 4.x from cdn
    polarion-id: CEPH-83573588
    module: test_ansible.py
    config:
      use_cdn: True
      build: '4.x'
      ansi_config:
        ceph_origin: repository
        ceph_repository: rhcs
        ceph_repository_type: cdn
        ceph_rhcs_version: 4
        ceph_stable_release: nautilus
        osd_scenario: lvm
        osd_auto_discovery: False
        ceph_stable_rh_storage: True
        containerized_deployment: true
        ceph_docker_image: "rhceph/rhceph-4-rhel8"
        ceph_docker_image_tag: "latest"
        ceph_docker_registry: "registry.redhat.io"
        copy_admin_key: true
        dashboard_enabled: True
        dashboard_admin_user: admin
        dashboard_admin_password: p@ssw0rd
        grafana_admin_user: admin
        grafana_admin_password: p@ssw0rd
        node_exporter_container_image: registry.redhat.io/openshift4/ose-prometheus-node-exporter:v4.6
        grafana_container_image: registry.redhat.io/rhceph/rhceph-4-dashboard-rhel8:4
        prometheus_container_image: registry.redhat.io/openshift4/ose-prometheus:v4.6
        alertmanager_container_image: registry.redhat.io/openshift4/ose-prometheus-alertmanager:v4.6
        ceph_conf_overrides:
            global:
              osd_pool_default_pg_num: 64
              osd_default_pool_size: 2
              osd_pool_default_pgp_num: 64
              mon_max_pg_per_osd: 1024
            mon:
              mon_allow_pool_delete: true
            client:
              rgw crypt require ssl: false
              rgw crypt s3 kms encryption keys: testkey-1=YmluCmJvb3N0CmJvb3N0LWJ1aWxkCmNlcGguY29uZgo=
                testkey-2=aWIKTWFrZWZpbGUKbWFuCm91dApzcmMKVGVzdGluZwo=
        cephfs_pools:
          - name: "cephfs_data"
            pgs: "8"
          - name: "cephfs_metadata"
            pgs: "8"
    desc: deploy ceph containerized 4.x cdn setup using ceph-ansible
    destroy-cluster: False
    abort-on-fail: true

- test:
    name: rbd-io
    module: rbd_faster_exports.py
    config:
        io-total: 100M
    desc: Perform export during read/write,resizing,flattening,lock operations

- test:
    name: Upgrade containerized ceph to 4.x latest
    polarion-id: CEPH-83573588
    module: test_ansible_upgrade.py
    config:
      build: '4.x'
      ansi_config:
        ceph_origin: distro
        ceph_stable_release: nautilus
        ceph_repository: rhcs
        ceph_rhcs_version: 4
        osd_scenario: lvm
        osd_auto_discovery: False
        ceph_stable: True
        ceph_stable_rh_storage: True
        fetch_directory: ~/fetch
        copy_admin_key: true
        containerized_deployment: true
        upgrade_ceph_packages: True
        dashboard_enabled: True
        dashboard_admin_user: admin
        dashboard_admin_password: p@ssw0rd
        grafana_admin_user: admin
        grafana_admin_password: p@ssw0rd
        node_exporter_container_image: registry.redhat.io/openshift4/ose-prometheus-node-exporter:v4.6
        grafana_container_image: registry.redhat.io/rhceph/rhceph-4-dashboard-rhel8:4
        prometheus_container_image: registry.redhat.io/openshift4/ose-prometheus:v4.6
        alertmanager_container_image: registry.redhat.io/openshift4/ose-prometheus-alertmanager:v4.6
        ceph_conf_overrides:
            global:
              osd_pool_default_pg_num: 64
              osd_default_pool_size: 2
              osd_pool_default_pgp_num: 64
              mon_max_pg_per_osd: 1024
            mon:
              mon_allow_pool_delete: true
            client:
              rgw crypt require ssl: false
              rgw crypt s3 kms encryption keys: testkey-1=YmluCmJvb3N0CmJvb3N0LWJ1aWxkCmNlcGguY29uZgo=
                testkey-2=aWIKTWFrZWZpbGUKbWFuCm91dApzcmMKVGVzdGluZwo=
    desc: Test Ceph-Ansible rolling update 4.x cdn -> 4.x latest
    abort-on-fail: True

- test:
    name: check-ceph-health
    module: exec.py
    config:
      cmd: ceph -s
      sudo: True
    desc: Check for ceph health debug info

- test:
    name: rgw sanity tests
    module: sanity_rgw.py
    config:
        script-name: test_multitenant_user_access.py
        config-file-name: test_multitenant_access.yaml
        timeout: 300
    desc: Perform rgw tests
