tests:
  - test:
      name: install ceph pre-requisites
      module: install_prereq.py
      abort-on-fail: true

  - test:
     name: ceph ansible
     module: test_ansible.py
     config:
       ansi_config:
           ceph_test: True
           ceph_origin: distro
           ceph_repository: rhcs
           osd_scenario: lvm
           osd_auto_discovery: False
           journal_size: 1024
           ceph_stable: True
           ceph_stable_rh_storage: True
           fetch_directory: ~/fetch
           copy_admin_key: true
           dashboard_enabled: False
           ceph_conf_overrides:
               global:
                 osd_pool_default_pg_num: 64
                 osd_default_pool_size: 2
                 osd_pool_default_pgp_num: 64
                 mon_max_pg_per_osd: 1024
               mon:
                 mon_allow_pool_delete: true
                 debug mon: 5
               mds:
                 mds_bal_split_size: 100
                 mds_bal_merge_size: 5
                 mds_bal_fragment_size_max: 10000
                 debug mds: 5
           cephfs_pools:
             - name: "cephfs_data"
               pgs: "8"
             - name: "cephfs_metadata"
               pgs: "8"
     desc: test cluster setup using ceph-ansible
     destroy-cluster: False
     abort-on-fail: true
  - test:
      abort-on-fail: true
      desc: "kernel update for CephFS kernel bugs"
      module: kernel_update.py
      name: kernel update
      polarion-id: "CEPH-83575404"
  - test:
      name: cephfs-mdsfailover-pinning-io
      module: CEPH-11227.py
      config:
        num_of_dirs: 1000
      polarion-id: CEPH-11227
      desc: MDSfailover on active-active mdss,performing client IOs with no pinning at the first,later pin 10 dirs with IOs
      abort-on-fail: false
  - test:
      name: cephfs-lifecycle ops
      module: CEPH-11333.py
      polarion-id: CEPH-11333
      desc: Perfrom cephfs lifecycle ops like delete cephfs,recreate cephfs
      abort-on-fail: false
  - test:
      name: multi-client-rw-io
      module: CEPH-10528_10529.py
      polarion-id: CEPH-10528,CEPH-10529
      desc: Single CephFS on multiple clients,performing IOs and checking file locking mechanism
      abort-on-fail: false
  - test:
      name: read-write-del-ops
      module: CEPH-11219.py
      polarion-id: CEPH-11219,CEPH-11226,CEPH-11224
      config:
        num_of_osds: 12
      desc: Mount CephFS on multiple clients perform read and write operation on same file from different clients and perform delete ops
      abort-on-fail: false
  - test:
      name: cephfs-io
      module: CEPH-11220.py
      polarion-id: CEPH-11220
      desc: Mount CephFS on multiple clients, On same directory perform write from some clients and do read that data from some clients
      abort-on-fail: false
  - test:
       name: cephfs-rsync
       module: CEPH-11298.py
       polarion-id: CEPH-11298
       desc: Mount CephFS on multiple clients and rsync files and directories to outside the filesystem and vice-versa
       abort-on-fail: false
  - test:
       name: cephfs-filelayouts
       module: CEPH-11334.py
       polarion-id: CEPH-11334
       desc: Mount CephFS on multiple clients and perform file layout operations
       abort-on-fail: false
  - test:
       name: cephfs_client-permissions
       module: CEPH-11338.py
       polarion-id: CEPH-11338
       desc: Mount CephFS on multiple clients,give various permissions to client like only read,write etc
       abort-on-fail: false
  - test:
       name: nfs-ganesha_with_cephfs
       module: nfs-ganesha_basics.py
       desc: Mount cephfs on clients,configure nfs-ganesha on nfs server,do mount on any client and do IOs
       polarion-id: CEPH-11308
       abort-on-fail: false
  - test:
       name: client-eviction
       module: CEPH-11335.py
       polarion-id: CEPH-11335
       desc: Mount CephFS on multiple clients and perform client eviction
       abort-on-fail: false
  - test:
       name: cephfs_client_authorize
       module: client_authorize.py
       polarion-id: CEPH-83574483
       desc: client authorize test for cephfs
       abort-on-fail: false
  - test:
      name: cephfs_tier1_ops
      module: cephfs_tier1_ops.py
      polarion-id: CEPH-83573447
      desc: cephfs tier1 operations
      abort-on-fail: false
  - test:
      name: cephfs subvolume authorize test
      desc: Test cephfs subvolume client authorize
      module: subvolume_authorize.py
      polarion-id: CEPH-83574596
      abort-on-fail: true
  - test:
      name: no recover session mount
      module: no_recover_session_mount.py
      polarion-id: CEPH-11260
      desc: test no recover session mount by blocking the client node
      abort-on-fail: false

