# Test-Case:
#   Perform cephadm operations with selinux enabled using cephadm ansible modules
#
# Cluster Configuration:
#   conf/pacific/cephadm/tier-1_5node_cephadm_bootstrap.yaml
#------------------------------------------------------------------------------

tests:
  - test:
      name: Install ceph pre-requisites
      desc: installation of ceph pre-requisites
      module: install_prereq.py
      abort-on-fail: true

  - test:
      name: Bootstrap cluster with selinux set to Permissive
      desc: Execute 'playbooks/bootstrap-cluster.yaml' playbook
      polarion-id: CEPH-83573579
      module: test_cephadm_ansible_bootstrap.py
      config:
        bootstrap:
          playbook: cephadm-bootstrap.yaml
          set_selinux: permissive  # permissive or enforcing
          module_args:
            mon_ip: node1
      abort-on-fail: true

  - test:
      name: Add host with labels to cluster using cephadm-ansible wrapper modules
      desc: Execute 'playbooks/add-host-to-cluster.yaml' playbook
      polarion-id: CEPH-83575203
      module: test_cephadm_ansible_operations.py
      config:
        ceph_orch_host:
          playbook: add-ceph-orch-host.yaml
          module_args:
            name: node2
            address: node2
            labels: osd.1
      abort-on-fail: true

  - test:
      name: Deploy OSD service to cluster using cephadm-ansible wrapper modules
      desc: Execute 'deploy-osd-service.yaml' playbook
      polarion-id: CEPH-83575213
      module: test_cephadm_ansible_operations.py
      config:
        ceph_orch_apply:
          playbook: deploy-osd-service.yaml
          module_args:
            label: osd.1

  - test:
      name: Add host with labels to cluster using cephadm-ansible wrapper modules
      desc: Execute 'add-host-to-cluster.yaml' playbook
      polarion-id: CEPH-83575203
      module: test_cephadm_ansible_operations.py
      config:
        ceph_orch_host:
          playbook: add-ceph-orch-host.yaml
          module_args:
            name: node3
            address: node3
            labels: osd.2
      abort-on-fail: true

  - test:
      name: Deploy OSD service to cluster using cephadm-ansible wrapper modules
      desc: Execute 'deploy-osd-service.yaml' playbook
      polarion-id: CEPH-83575213
      module: test_cephadm_ansible_operations.py
      config:
        ceph_orch_apply:
          playbook: deploy-osd-service.yaml
          module_args:
            label: osd.2

  - test:
      name: Add host with labels to cluster using cephadm-ansible wrapper modules
      desc: Execute 'add-host-to-cluster.yaml' playbook
      polarion-id: CEPH-83575203
      module: test_cephadm_ansible_operations.py
      config:
        ceph_orch_host:
          playbook: add-ceph-orch-host.yaml
          module_args:
            name: node4
            address: node4
            labels: osd.3
      abort-on-fail: true

  - test:
      name: Deploy OSD service to cluster using cephadm-ansible wrapper modules
      desc: Execute 'deploy-osd-service.yml' playbook
      polarion-id: CEPH-83575213
      module: test_cephadm_ansible_operations.py
      config:
        ceph_orch_apply:
          playbook: deploy-osd-service.yaml
          module_args:
            label: osd.3

  - test:
      name: Check cluster status when nodes are performed with reboot
      desc: Perform reboot and check ceph status
      polarion-id: CEPH-83573754
      module: test_verify_cluster_health_after_reboot.py
      config:
        action: node-reboot
      abort-on-fail: true

  - test:
      name: Check cluster status when daemon services are started restart stop with systemctl
      desc: Verify systemctl ops of services
      polarion-id: CEPH-83573755
      module: test_verify_cluster_health_after_reboot.py
      config:
        action: service-state
      abort-on-fail: true

  - test:
      name: Verify 'ceph health detail' output
      desc: Verify ceph health detail info when mon node is offline
      polarion-id: CEPH-83575328
      module: test_ceph_health_detail_when_mon_offline.py
