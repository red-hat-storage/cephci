# Tier - 2: Execute S3Tests using self-signed certificate
#
# Requires the following keys in cephci.yaml
#
#   vault:
#        url: http://<vault-server>/
#        agent:
#          auth: agent
#          engine: transit
#          role-id: <role-id>
#          secret-id: <secret-id>
#          prefix: /v1/<path>
#
---
tests:
  - test:
      abort-on-fail: true
      desc: Install software pre-requisites for cluster deployment.
      module: install_prereq.py
      name: setup pre-requisites

  - test:
      abort-on-fail: true
      config:
        verify_cluster_health: true
        steps:
          - config:
              command: bootstrap
              service: cephadm
              args:
                mon-ip: node1
                orphan-initial-daemons: true
                skip-monitoring-stack: true
                initial-dashboard-password: admin@123
                dashboard-password-noupdate: true
          - config:
              command: add_hosts
              service: host
              args:
                attach_ip_address: true
                labels: apply-all-labels
          - config:
              command: apply
              service: mgr
              args:
                placement:
                  label: mgr
          - config:
              command: apply
              service: mon
              args:
                placement:
                  label: mon
          - config:
              command: apply
              service: osd
              args:
                all-available-devices: true
          - config:
              args:
                - "ceph osd erasure-code-profile set rgwecprofile01 k=4 m=2"
                - "crush-failure-domain=host crush-device-class=hdd"
              command: shell
          - config:
              args:
                - "ceph osd pool create default.rgw.buckets.data 32 32"
                - "erasure rgwecprofile01"
              command: shell
          - config:
              args:
                - "ceph osd pool create default.rgw.buckets.index 32 32"
              command: shell
          - config:
              args:
                - "ceph osd pool application enable"
                - "default.rgw.buckets.data rgw"
              command: shell
          - config:
              args:
                - "ceph osd pool application enable"
                - "default.rgw.buckets.index rgw"
              command: shell
          - config:
              command: apply_spec
              service: orch
              specs:
                - service_type: rgw
                  service_id: rgw.ssl
                  placement:
                    nodes:
                      - node7
                  spec:
                    ssl: true
                    rgw_frontend_ssl_certificate: create-cert
      desc: RHCS cluster deployment using cephadm.
      polarion-id: CEPH-83574478
      destroy-cluster: false
      module: test_cephadm.py
      name: deploy cluster

  - test:
      name: Monitoring Services deployment
      desc: Add monitoring services using spec file.
      module: test_cephadm.py
      polarion-id: CEPH-83574727
      config:
        steps:
          - config:
              command: apply_spec
              service: orch
              validate-spec-services: true
              specs:
                - service_type: prometheus
                  placement:
                    count: 1
                    nodes:
                      - node1
                - service_type: grafana
                  placement:
                    nodes:
                      - node1
                - service_type: alertmanager
                  placement:
                    count: 1
                - service_type: node-exporter
                  placement:
                    host_pattern: "*"
                - service_type: crash
                  placement:
                    host_pattern: "*"

  - test:
      abort-on-fail: true
      config:
        command: add
        id: client.1
        node: node8
        install_packages:
          - ceph-common
        copy_admin_keyring: true
      desc: Configure the RGW client system
      destroy-cluster: false
      module: test_client.py
      name: configure client
      polarion-id: CEPH-83573758

  - test:
      abort-on-fail: true
      config:
        install:
          - agent
      desc: Setup and configure vault agent
      destroy-cluster: false
      module: install_vault.py
      name: configure vault agent
      polarion-id: CEPH-83575226

  - test:
      abort-on-fail: false
      config:
        branch: ceph-pacific
        kms_keyid: testKey01
      desc: S3tests
      destroy-cluster: false
      module: test_s3.py
      name: execute s3tests
      polarion-id: CEPH-10361
      comments: Known issue - Ceph tracker 55614

  - test:
      name: Deploy RGW Ingress daemon
      abort-on-fail: true
      desc: Add RGW and HA Proxy services using spec file.
      module: test_cephadm.py
      polarion-id: CEPH-83574607
      config:
        steps:
          - config:
              command: apply_spec
              service: orch
              specs:
                - service_type: rgw
                  service_id: my-rgw
                  placement:
                    nodes:
                      - node4
                      - node5
                  spec:
                    rgw_frontend_port: 8080
          - config:
              command: shell
              args: # sleep to get all services deployed
                - sleep
                - "60"
          - config:
              command: apply_spec
              service: orch
              validate-spec-services: true
              specs:
                - service_type: ingress
                  service_id: rgw.my-rgw
                  placement:
                    nodes:
                      - node4
                      - node5
                  spec:
                    backend_service: rgw.my-rgw
                    virtual_ip: 127.1.1.100/8
                    virtual_interface_networks:
                      # rhos-d network id's
                      - '10.0.208.0/22'  # provider_net_cci_12
                      - '10.0.204.0/22'  # provider_net_cci_11
                      - '10.0.108.0/22'  # provider_net_cci_9
                      - '10.0.104.0/22'  # provider_net_cci_8
                      - '10.0.100.0/22'  # provider_net_cci_7
                      - '10.0.96.0/22'  # provider_net_cci_6
                      - '10.0.152.0/22'  # provider_net_cci_5
                      - '10.0.148.0/22'  # provider_net_cci_4
                      # rhos-01 network id's
                      - '10.0.195.0/24'  # shared_net_12
                      - '10.0.194.0/24'  # shared_net_11
                      - '10.0.192.0/24'  # shared_net_9
                      - '10.0.191.0/24'  # shared_net_8
                      - '10.0.190.0/24'  # shared_net_7
                      - '10.0.189.0/24'  # shared_net_6
                      - '10.0.188.0/24'  # shared_net_5
                      - '10.0.201.0/24'  # shared_net_4
                    frontend_port: 443
                    monitor_port: 1967
                    ssl_cert: create-cert
