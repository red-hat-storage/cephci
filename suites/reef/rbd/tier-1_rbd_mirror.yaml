#===============================================================================================
# Tier-level: 1
# Test-Suite: tier-1_rbd_mirror.yaml
# Test-Case: Configure RBD Mirror setup and run IOs
# Polarion ID : CEPH-83573329 - RBD HA MirroringDraft
#
# Cluster Configuration:
#    Conf file - conf/reef/rbd/5-node-2-clusters.yaml
#    No of Clusters : 2
#    Node 2 must to be a client node
#
# The following evaluations are carried out
#   (1) Configures RBD Mirroring on cephadm
#   (2) Creates Pool Image and enables Mirroring
#   (3) Runs IO using rbd bench
#===============================================================================================
tests:
  - test:
      name: setup install pre-requisistes
      desc: Setup phase to deploy the required pre-requisites for running the tests.
      module: install_prereq.py
      abort-on-fail: true
  - test:
      abort-on-fail: true
      clusters:
        ceph-rbd1:
          config:
            verify_cluster_health: true
            steps:
              - config:
                  command: bootstrap
                  service: cephadm
                  args:
                    mon-ip: node1
                    orphan-initial-daemons: true
                    skip-monitoring-stack: true
              - config:
                  command: add_hosts
                  service: host
                  args:
                    attach_ip_address: true
                    labels: apply-all-labels
              - config:
                  command: apply
                  service: mgr
                  args:
                    placement:
                      label: mgr
              - config:
                  command: apply
                  service: mon
                  args:
                    placement:
                      label: mon
              - config:
                  command: apply
                  service: osd
                  args:
                    all-available-devices: true
        ceph-rbd2:
          config:
            verify_cluster_health: true
            steps:
              - config:
                  command: bootstrap
                  service: cephadm
                  args:
                    registry-url: registry.redhat.io
                    mon-ip: node1
                    orphan-initial-daemons: true
                    skip-monitoring-stack: true
              - config:
                  command: add_hosts
                  service: host
                  args:
                    attach_ip_address: true
                    labels: apply-all-labels
              - config:
                  command: apply
                  service: mgr
                  args:
                    placement:
                      label: mgr
              - config:
                  command: apply
                  service: mon
                  args:
                    placement:
                      label: mon
              - config:
                  command: apply
                  service: osd
                  args:
                    all-available-devices: true
      desc: RBD Mirror cluster deployment using cephadm
      destroy-cluster: false
      module: test_cephadm.py
      name: deploy cluster
  - test:
        abort-on-fail: true
        clusters:
          ceph-rbd1:
            config:
              command: add
              id: client.1
              node: node2
              install_packages:
                - ceph-common
              copy_admin_keyring: true
          ceph-rbd2:
            config:
                command: add
                id: client.1
                node: node2
                install_packages:
                    - ceph-common
                copy_admin_keyring: true
        desc: Configure the client system 1
        destroy-cluster: false
        module: test_client.py
        name: configure client
  - test:
      abort-on-fail: true
      clusters:
        ceph-rbd1:
          config:
            verify_cluster_health: true
            steps:
              - config:
                  command: apply
                  service: rbd-mirror
                  args:
                    placement:
                      label: rbd-mirror
        ceph-rbd2:
          config:
            verify_cluster_health: true
            steps:
              - config:
                  command: apply
                  service: rbd-mirror
                  args:
                    placement:
                      label: rbd-mirror
      desc: RBD Mirror daemon deployment using cephadm
      destroy-cluster: false
      module: test_cephadm.py
      name: deploy rbd-mirror daemon
  - test:
      abort-on-fail: true
      clusters:
        ceph-rbd1:
          config:
            cephadm: true
            commands:
              - "ceph config set mon mon_allow_pool_delete true"
        ceph-rbd2:
          config:
            cephadm: true
            commands:
              - "ceph config set mon mon_allow_pool_delete true"
      desc: Enable mon_allow_pool_delete to True for deleting the pools
      module: exec.py
      name: configure mon_allow_pool_delete to True
  - test:
      name: test_rbd_mirror
      module: test_rbd_mirror.py
      clusters:
        ceph-rbd1:
          config:
            imagesize: 2G
            io-total: 200M
            resize_to: 5G
      polarion-id: CEPH-83573332
      desc: Create RBD mirrored image in pools  and run IOs
  - test:
      name: test_rbd_mirror_image
      module: test_rbd_mirror_image.py
      clusters:
        ceph-rbd1:
          config:
            imagesize: 2G
            io-total: 200M
      polarion-id: CEPH-83573619,CEPH-83573620
      desc: Create RBD mirrored images and run IOs
  - test:
      name: test_rbd_mirror_rename_image
      module: test_rbd_mirror_rename_image.py
      clusters:
        ceph-rbd1:
          config:
            imagesize: 2G
            io-total: 200M
      polarion-id: CEPH-83573614
      desc: Rename primary image and check on secondary for this change
  - test:
      name: test_rbd_mirror_daemon_status
      module: test_rbd_mirror_daemon_status.py
      clusters:
        ceph-rbd1:
          config:
            imagesize: 2G
            io-total: 200M
      polarion-id: CEPH-83573760
      desc: Verify rbd mirror and daemon status on cluster
