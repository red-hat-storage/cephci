#Objective: Testing single site upgrade from RHCS 7.1 G.A latest to 8.x latest build
#platform : RHEL-9
#conf: conf/squid/rgw/tier-0_rgw.yaml

tests:
  - test:
      abort-on-fail: true
      desc: Install software pre-requisites for cluster deployment.
      module: install_prereq.py
      name: setup pre-requisites

  - test:
      abort-on-fail: true
      config:
        verify_cluster_health: true
        steps:
          - config:
              command: bootstrap
              service: cephadm
              args:
                rhcs-version: 7.1
                release: rc
                registry-url: registry.redhat.io
                mon-ip: node1
                orphan-initial-daemons: true
                skip-monitoring-stack: true
          - config:
              command: add_hosts
              service: host
              args:
                attach_ip_address: true
                labels: apply-all-labels
          - config:
              command: apply
              service: mgr
              args:
                placement:
                  label: mgr
          - config:
              command: apply
              service: mon
              args:
                placement:
                  label: mon
          - config:
              command: apply
              service: osd
              args:
                all-available-devices: true
          - config:
              command: apply
              service: rgw
              pos_args:
                - rgw.1
              args:
                placement:
                  label: rgw
      desc: bootstrap and deployment services with label placements.
      polarion-id: CEPH-83573777
      destroy-cluster: false
      module: test_cephadm.py
      name: Deploy RHCS cluster using cephadm


  - test:
      abort-on-fail: true
      config:
        command: add
        id: client.1
        node: node6
        install_packages:
          - ceph-common
        copy_admin_keyring: true
      desc: Configure the RGW client system
      destroy-cluster: false
      module: test_client.py
      name: configure client
      polarion-id: CEPH-83573758

  - test:
      name: Mbuckets_with_Nobjects with etag verification pre upgrade
      desc: test etag verification
      module: sanity_rgw.py
      polarion-id: CEPH-83574871
      config:
        script-name: test_Mbuckets_with_Nobjects.py
        config-file-name: test_Mbuckets_with_Nobjects_etag.yaml

  - test:
      name: Dynamic Resharding tests pre upgrade
      desc: Resharding test - dynamic
      polarion-id: CEPH-83571740 # also applies to ceph-11479, ceph-11477
      module: sanity_rgw.py
      config:
        script-name: test_dynamic_bucket_resharding.py
        config-file-name: test_dynamic_resharding_without_bucket_delete.yaml

  - test:
      name: Manual Resharding tests pre upgrade
      desc: Resharding test - manual
      polarion-id: CEPH-83571740
      module: sanity_rgw.py
      config:
        script-name: test_dynamic_bucket_resharding.py
        config-file-name: test_manual_resharding_without_bucket_delete.yaml

  - test:
      name: Dynamic Resharding tests with version pre upgrade
      desc: Resharding test - dynamic
      polarion-id: CEPH-83571740
      module: sanity_rgw.py
      config:
        script-name: test_dynamic_bucket_resharding.py
        config-file-name: test_dynamic_resharding_with_version_without_bucket_delete.yaml

  - test:
      name: S3CMD small and multipart object download pre upgrade
      desc: S3CMD small and multipart object download or GET
      polarion-id: CEPH-83575477
      module: sanity_rgw.py
      config:
        script-name: ../s3cmd/test_s3cmd.py
        config-file-name: ../../s3cmd/configs/test_get_s3cmd.yaml

  # upgrade cluster
  - test:
      name: Test rename of large object using sts user through AWS
      desc: Test rename of large object using sts user through AWS
      polarion-id: CEPH-83575419
      module: sanity_rgw.py
      config:
        script-name: ../aws/test_sts_rename_large_object.py
        config-file-name: ../../aws/configs/test_sts_rename_large_object.yaml

  # upgrade cluster
  - test:
      name: Parallel run
      desc: RGW upgarde and IO parallelly.
      module: test_parallel.py
      parallel:
        - test:
            desc: test to create "M" no of buckets and "N" no of objects with download
            module: sanity_rgw.py
            name: Test download with M buckets with N objects
            polarion-id: CEPH-14237
            config:
              script-name: test_Mbuckets_with_Nobjects.py
              config-file-name: test_Mbuckets_with_Nobjects_download.yaml
        - test:
            name: Upgrade cluster to latest 8.x ceph version
            desc: Upgrade cluster to latest version
            module: test_cephadm_upgrade.py
            polarion-id: CEPH-83573791
            abort-on-fail: true
            verify_cluster_health: true
            config:
              command: start
              service: upgrade
              base_cmd_args:
                verbose: true

  # Post Upgrade tests
  - test:
      desc: Retrieve the versions of the cluster
      module: exec.py
      name: post upgrade gather version
      polarion-id: CEPH-83575200
      config:
        cephadm: true
        commands:
          - "ceph versions"

# Post upgrade tests

  - test:
      name: S3CMD small and multipart object download post upgrade
      desc: S3CMD small and multipart object download or GET
      polarion-id: CEPH-83575477
      module: sanity_rgw.py
      config:
        script-name: ../s3cmd/test_s3cmd.py
        config-file-name: ../../s3cmd/configs/test_get_s3cmd.yaml

  - test:
      name: Manual Resharding tests post upgrade
      desc: Resharding test - manual
      polarion-id: CEPH-83571740
      module: sanity_rgw.py
      config:
        script-name: test_dynamic_bucket_resharding.py
        config-file-name: test_manual_resharding_without_bucket_delete.yaml

  - test:
      name: Dynamic Resharding tests with version post upgrade
      desc: Resharding test - dynamic
      polarion-id: CEPH-83571740
      module: sanity_rgw.py
      config:
        script-name: test_dynamic_bucket_resharding.py
        config-file-name: test_dynamic_resharding_with_version_without_bucket_delete.yaml

  - test:
      name: test storage policy to use customized placement for S3
      desc: Test storage policy to use customized placement for S3
      polarion-id: CEPH-9337
      module: sanity_rgw.py
      config:
        script-name: test_storage_policy.py
        config-file-name: test_storage_policy_s3.yaml

  - test:
      name: test storage policy to use customized placement for Swift
      desc: Test storage policy to use customized placement for Swift
      polarion-id: CEPH-9336
      module: sanity_rgw.py
      config:
        script-name: test_storage_policy.py
        config-file-name: test_storage_policy_swift.yaml
