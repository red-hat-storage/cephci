#===============================================================================================
#-------------------------------------
#---    Test Suite for Nfs Ganesha tests for QoS vers 4.2---
#-------------------------------------
# Conf: conf/squid/nfs/1admin-7node-3client.yaml
# Smoke test cases for
#    - Bootstrap
#    - Host management
#    - Configure nfs-ganesha on nfs server,do mount on any client and do IOs
#    - Test NFS cluster and export create
#
#===============================================================================================
tests:
  - test:
      abort-on-fail: true
      desc: Install software pre-requisites for cluster deployment.
      module: install_prereq.py
      name: setup pre-requisites

  - test:
      abort-on-fail: true
      config:
        steps:
          - config:
              command: bootstrap
              service: cephadm
              args:
                mon-ip: node1
          - config:
              command: add_hosts
              service: host
              args:
                attach_ip_address: true
                labels: apply-all-labels
          - config:
              command: apply
              service: osd
              args:
                all-available-devices: true
          - config:
              command: apply
              service: rgw
              pos_args:
                - rgw.1
              args:
                placement:
                  label: rgw
          - config:
              args:
                - "ceph fs volume create cephfs"
              command: shell
          - config:
              args:
                placement:
                  label: mds
              base_cmd_args:
                verbose: true
              command: apply
              pos_args:
                - cephfs
              service: mds
          - config:
              args:
                - "ceph osd pool create rbd"
              command: shell
          - config:
              args:
                - "rbd pool init rbd"
              command: shell
      desc: bootstrap and deploy services.
      destroy-cluster: false
      polarion-id: CEPH-83573713
      module: test_cephadm.py
      name: Deploy cluster using cephadm

  - test:
      abort-on-fail: true
      config:
        command: add
        id: client.1
        node: node4
        install_packages:
          - ceph-common
          - ceph-fuse
        copy_admin_keyring: true
      desc: Configure the RGW,RBD client system
      destroy-cluster: false
      module: test_client.py
      name: configure client

  - test:
      abort-on-fail: true
      config:
        command: add
        id: client.2
        node: node5
        install_packages:
          - ceph-common
          - ceph-fuse
        copy_admin_keyring: true
      desc: Configure the RGW,RBD client system
      destroy-cluster: false
      module: test_client.py
      name: configure client

  - test:
      abort-on-fail: true
      config:
        command: add
        id: client.3
        node: node6
        install_packages:
          - ceph-common
          - ceph-fuse
        copy_admin_keyring: true
      desc: Configure the RGW,RBD client system
      destroy-cluster: false
      module: test_client.py
      name: configure client

  - test:
      abort-on-fail: true
      config:
        command: add
        id: client.4
        node: node7
        install_packages:
          - ceph-common
          - ceph-fuse
        copy_admin_keyring: true
      desc: Configure the RGW,RBD client system
      destroy-cluster: false
      module: test_client.py
      name: configure client

  - test:
      name: Qos PerShare enablement on Cluster level with nfs with service restart
      module: test_nfs_qos_on_cluster_level_enablement.py
      desc: Verify qos Pershare enablement on cluster level
      polarion-id: CEPH-83611390
      abort-on-fail: false
      config:
        cephfs_volume : cephfs
        cluster_name : cephfs-nfs
        max_export_write_bw : 8MB
        max_export_read_bw : 8MB
        max_client_write_bw : 8MB
        max_client_read_bw: 8MB
        qos_type : PerShare
        operation : restart

  - test:
      name: Qos PerClient enablement on Cluster level with nfs with service restart
      module: test_nfs_qos_on_cluster_level_enablement.py
      desc: Verify qos PerClient enablement on cluster level
      polarion-id: CEPH-83614246
      abort-on-fail: false
      config:
        cephfs_volume: cephfs
        cluster_name: cephfs-nfs
        max_export_write_bw: 8MB
        max_export_read_bw: 8MB
        max_client_write_bw: 8MB
        max_client_read_bw: 8MB
        qos_type: PerClient
        operation: restart

  - test:
      name: Qos PerShare_PerClient enablement on Cluster level with nfs with service restart
      module: test_nfs_qos_on_cluster_level_enablement.py
      desc: Verify qos PerShare_PerClient enablement on cluster level
      polarion-id: CEPH-83614247
      abort-on-fail: false
      config:
        cephfs_volume: cephfs
        cluster_name: cephfs-nfs
        max_export_write_bw: 8MB
        max_export_read_bw: 8MB
        max_client_write_bw: 8MB
        max_client_read_bw: 8MB
        qos_type: PerShare_PerClient
        operation: restart

  - test:
      name: Qos enablement PerShare-PerClient on export level with nfs service with restart
      module: test_nfs_qos_on_export_level_enablement.py
      desc: Verify qos PerShare-PerClient enablement on export level
      polarion-id: CEPH-83613691
      abort-on-fail: false
      config:
        cephfs_volume : cephfs
        cluster_name : cephfs-nfs
        cluster_bw :
          - max_export_write_bw : 100MB
            max_export_read_bw : 100MB
            max_client_write_bw : 100MB
            max_client_read_bw: 100MB
        export_bw:
          - max_export_write_bw: 8MB
            max_export_read_bw: 8MB
            max_client_write_bw: 8MB
            max_client_read_bw: 8MB
        qos_type : PerShare_PerClient
        operation : restart

  - test:
      name: Qos enablement PerShare on export level with nfs service with restart
      module: test_nfs_qos_on_export_level_enablement.py
      desc: Verify qos Pershare enablement on export level
      polarion-id: CEPH-83614248
      abort-on-fail: false
      config:
        cephfs_volume: cephfs
        cluster_name: cephfs-nfs
        cluster_bw:
          - max_export_write_bw: 100MB
            max_export_read_bw: 100MB
            max_client_write_bw: 100MB
            max_client_read_bw: 100MB
        export_bw:
          - max_export_write_bw: 8MB
            max_export_read_bw: 8MB
            max_client_write_bw: 8MB
            max_client_read_bw: 8MB
        qos_type: PerShare
        operation: restart

  - test:
      name: Qos enablement PerShare-combined_bw value for export level with nfs service with restart
      module: test_nfs_qos_on_export_level_enablement.py
      desc: Verify qos PerShare-combined_bw value enablement on export level
      polarion-id: CEPH-83616913
      abort-on-fail: false
      config:
        cephfs_volume: cephfs
        cluster_name: cephfs-nfs
        cluster_bw:
          - max_export_combined_bw: 100MB
        export_bw:
          - max_export_combined_bw: 8MB
        qos_type: PerShare
        operation: restart

  - test:
      name: Qos enablement PerShare_PerClient-combined_bw value for export level with nfs service with restart
      module: test_nfs_qos_on_export_level_enablement.py
      desc: Verify qos PerShare_PerClient-combined_bw value enablement on export level
      polarion-id: CEPH-83616914
      abort-on-fail: false
      config:
        cephfs_volume: cephfs
        cluster_name: cephfs-nfs
        cluster_bw:
          - max_client_combined_bw: 100MB
            max_export_combined_bw: 100MB
        export_bw:
          - max_client_combined_bw: 8MB
            max_export_combined_bw: 8MB
        qos_type: PerShare_PerClient
        operation: restart

  - test:
      name: Qos PerShare-combined_bw enablement on Cluster level with nfs with service restart
      module: test_nfs_qos_on_cluster_level_enablement.py
      desc: Verify qos PerShare-combined_bw enablement on cluster level
      polarion-id: CEPH-83616910
      abort-on-fail: false
      config:
        cephfs_volume : cephfs
        cluster_name : cephfs-nfs
        max_export_combined_bw: 8MB
        qos_type : PerShare
        operation : restart

  - test:
      name: Qos PerClient-combined_bw enablement on Cluster level with nfs with service restart
      module: test_nfs_qos_on_cluster_level_enablement.py
      desc: Verify qos PerClient-combined_bw enablement on cluster level
      polarion-id: CEPH-83616911
      abort-on-fail: false
      config:
        cephfs_volume: cephfs
        cluster_name: cephfs-nfs
        max_client_combined_bw: 8MB
        qos_type: PerClient
        operation: restart

  - test:
      name: Qos PerShare_PerClient-combined_bw enablement on Cluster level with nfs with service restart
      module: test_nfs_qos_on_cluster_level_enablement.py
      desc: Verify qos PerShare_PerClient-combined_bw enablement on cluster level
      polarion-id: CEPH-83616912
      abort-on-fail: false
      config:
        cephfs_volume: cephfs
        cluster_name: cephfs-nfs
        max_export_combined_bw: 8MB
        max_client_combined_bw: 8MB
        qos_type: PerShare_PerClient
        operation: restart

  - test:
      name: deploy nfs ganesha with qos per share using spec file
      desc: Deploy nfs ganesha with qos per share using spec file and verify
      polarion-id: CEPH-83621553
      module: nfs_verify_qos_via_specfile_PerShare.py
      config:
        nfs_version: 4.2
        clients: 4
        port: 2049
        spec:
          service_type: nfs
          service_id: nfs
          placement:
            host_pattern: '*'
          spec:
              cluster_qos_config:
                combined_rw_bw_control: false
                enable_bw_control: true
                enable_qos: true
                max_export_read_bw: 20MB
                max_export_write_bw: 20MB
                qos_type: PerShare
