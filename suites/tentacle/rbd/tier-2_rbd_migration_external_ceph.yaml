#===============================================================================================
# Tier-level: 2
# Test-Suite: tier-2_rbd_migration_external_ceph.yaml
#
# Cluster Configuration:
#    cephci/conf/tentacle/rbd/5-node-2-clusters.yaml
#    No of Clusters : 2
#    Each cluster configuration
#    5-Node cluster(RHEL-8.3 and above)
#    3 MONS, 2 MGR, 3 OSD, 1 Client
#     Node1 - Mon, Mgr, Installer
#     Node2 - client
#     Node3 - OSD, MON, MGR
#     Node4 - OSD, MON
#     Node5 - OSD,
#===============================================================================================
tests:
  - test:
      name: setup install pre-requisistes
      desc: >
        Setup phase to deploy the required pre-requisites
        for running the tests.
      module: install_prereq.py
      abort-on-fail: true

  - test:
      abort-on-fail: true
      clusters:
        ceph-rbd1:
          config:
            verify_cluster_health: true
            steps:
              - config:
                  command: bootstrap
                  service: cephadm
                  args:
                    mon-ip: node1
                    orphan-initial-daemons: true
                    skip-monitoring-stack: true
              - config:
                  command: add_hosts
                  service: host
                  args:
                    attach_ip_address: true
                    labels: apply-all-labels
              - config:
                  command: apply
                  service: mgr
                  args:
                    placement:
                      label: mgr
              - config:
                  command: apply
                  service: mon
                  args:
                    placement:
                      label: mon
              - config:
                  command: apply
                  service: osd
                  args:
                    all-available-devices: true
        ceph-rbd2:
          config:
            verify_cluster_health: true
            steps:
              - config:
                  command: bootstrap
                  service: cephadm
                  args:
                    mon-ip: node1
                    orphan-initial-daemons: true
                    skip-monitoring-stack: true
              - config:
                  command: add_hosts
                  service: host
                  args:
                    attach_ip_address: true
                    labels: apply-all-labels
              - config:
                  command: apply
                  service: mgr
                  args:
                    placement:
                      label: mgr
              - config:
                  command: apply
                  service: mon
                  args:
                    placement:
                      label: mon
              - config:
                  command: apply
                  service: osd
                  args:
                    all-available-devices: true
      desc: Two ceph cluster deployment for external ceph migration testing
      destroy-clster: false
      module: test_cephadm.py
      name: deploy two ceph cluster

  - test:
      abort-on-fail: true
      clusters:
        ceph-rbd1:
          config:
            command: add
            id: client.1
            node: node2
            install_packages:
              - ceph-common
              - fio
            copy_admin_keyring: true
        ceph-rbd2:
          config:
            command: add
            id: client.1
            node: node2
            install_packages:
              - ceph-common
              - fio
            copy_admin_keyring: true
      desc: Configure the client node for both the clusters
      destroy-cluster: false
      module: test_client.py
      name: configure client

  - test:
      desc: Enable mon_allow_pool_delete to True for deleting the pools
      module: exec.py
      name: configure mon_allow_pool_delete to True
      abort-on-fail: true
      config:
        cephadm: true
        commands:
          - "ceph config set mon mon_allow_pool_delete true"

  - test:
      desc: Install rbd-nbd, qemu-img and remove any epel packages
      module: exec.py
      name: Install RBD packages
      config:
        sudo: true
        commands:
          - "rm -rf /etc/yum.repos.d/epel*"
          - "dnf install rbd-nbd -y --nogpgcheck"
          - "dnf install qemu-img -y --nogpgcheck"

  - test:
      name: Test image migration with external ceph cluster
      desc: live migration with external ceph native data format
      module: test_rbd_migration_external_native_image.py
      clusters:
        ceph-rbd1:
          config:
            rep_pool_config:
              num_pools: 1
              num_images: 1
              size: 4G
              create_pool_parallely: true
              create_image_parallely: true
              test_ops_parallely: true
              io_size: 1G
            ec_pool_config:
              num_pools: 1
              num_images: 1
              size: 4G
              create_pool_parallely: true
              create_image_parallely: true
              test_ops_parallely: true
              io_size: 1G
      polarion-id: CEPH-83597689

  - test:
      name: Test image migration with external ceph cluster for qcow data
      desc: live migration with external ceph qcow data format
      module: test_rbd_migration_external_qcow_image.py
      clusters:
        ceph-rbd1:
          config:
            rep_pool_config:
              num_pools: 1
              num_images: 1
              size: 4G
              create_pool_parallely: true
              create_image_parallely: true
              test_ops_parallely: true
              io_size: 1G
            ec_pool_config:
              num_pools: 1
              num_images: 1
              size: 4G
              create_pool_parallely: true
              create_image_parallely: true
              test_ops_parallely: true
              io_size: 1G
      polarion-id: CEPH-83597837

  - test:
      name: Test Live migration of images with snapshots and clones
      desc: >
        Verify live migration between two cluster of
        images with snapshots & clones
      module: test_rbd_migration_clones.py
      clusters:
        ceph-rbd1:
          config:
            rep_pool_config:
              num_pools: 1
              num_images: 1
              size: 4G
              create_pool_parallely: true
              create_image_parallely: true
              test_ops_parallely: true
              io_size: 1G
            ec_pool_config:
              num_pools: 1
              num_images: 1
              size: 4G
              create_pool_parallely: true
              create_image_parallely: true
              test_ops_parallely: true
              io_size: 1G
      polarion-id: CEPH-83597864

  - test:
      desc: >
        Live migration of rbd images with encryption from one cluster
        to another with native format
      clusters:
        ceph-rbd1:
          config:
            encryption_type:
              - luks1
              - luks2
            rep_pool_config:
              num_pools: 1
              num_images: 1
              size: 4G
            ec_pool_config:
              num_pools: 1
              num_images: 1
              size: 4G
            fio:
              size: 1G
              fs: ext4
              io: true
      module: test_rbd_live_migration_encryption_two_cluster.py
      name: Live migration of encrypted rbd images from one cluster to another
      polarion-id: CEPH-83597863

  - test:
      name: >
        Live migration of sparse import with an NBD
        source of RAW data format
      desc: >
        live migration of images with external data source as RAW data format
        from one ceph cluster to another ceph cluster with an NBD source.
      module: test_rbd_migration_external_nbd.py
      clusters:
        ceph-rbd1:
          config:
            rep_pool_config:
              num_pools: 1
              num_images: 1
              size: 4G
              create_pool_parallely: true
              create_image_parallely: true
              test_ops_parallely: true
              io_size: 1G
            ec_pool_config:
              num_pools: 1
              num_images: 1
              size: 4G
              create_pool_parallely: true
              create_image_parallely: true
              test_ops_parallely: true
              io_size: 1G
      polarion-id: CEPH-83598705

  - test:
      name: Test Live migration of namespace level images
      desc: live migration with namespace level RBD images
      module: test_rbd_migration_namespace_image.py
      clusters:
        ceph-rbd1:
          config:
            rep_pool_config:
              num_pools: 1
              num_images: 1
              size: 4G
              create_pool_parallely: true
              create_image_parallely: true
              test_ops_parallely: true
              io_size: 1G
            ec_pool_config:
              num_pools: 1
              num_images: 1
              size: 4G
              create_pool_parallely: true
              create_image_parallely: true
              test_ops_parallely: true
              io_size: 1G
      polarion-id: CEPH-83597865

  - test:
      desc: >
        Live migration of rbd clone images with encryption from one cluster
        to another with native format
      clusters:
        ceph-rbd1:
          config:
            rep_pool_config:
              num_pools: 1
              num_images: 1
              size: 4G
            ec_pool_config:
              num_pools: 1
              num_images: 1
              size: 4G
            fio:
              size: 1G
              fs: ext4
              io: true
      module: test_rbd_migration_clone_encryption.py
      name: Live migration of parent image with LUKS1 and child image with LUKS2
      polarion-id: CEPH-83598689

  - test:
      name: >
        Live migration of sparse import with an NBD
        source of QCOW data format
      desc: >
        live migration of images with external data source as qcow data format
        from one ceph cluster to another ceph cluster with an NBD source.
      module: test_rbd_migration_qcow_nbd.py
      clusters:
        ceph-rbd1:
          config:
            rep_pool_config:
              num_pools: 1
              num_images: 1
              size: 4G
              create_pool_parallely: true
              create_image_parallely: true
              test_ops_parallely: true
              io_size: 1G
            ec_pool_config:
              num_pools: 1
              num_images: 1
              size: 4G
              create_pool_parallely: true
              create_image_parallely: true
              test_ops_parallely: true
              io_size: 1G
      polarion-id: CEPH-83598692
