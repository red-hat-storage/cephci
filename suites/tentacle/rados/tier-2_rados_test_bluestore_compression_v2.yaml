# Conf: conf/tentacle/rados/7-node-cluster.yaml

tests:
  - test:
      name: setup install pre-requisistes
      desc: Setup phase to deploy the required pre-requisites for running the tests.
      module: install_prereq.py
      abort-on-fail: true

  - test:
      name: cluster deployment
      desc: Execute the cluster deployment workflow.
      module: test_cephadm.py
      polarion-id:
      config:
        verify_cluster_health: true
        steps:
          - config:
              command: bootstrap
              service: cephadm
              base_cmd_args:
                verbose: true
              args:
                registry-url: registry.redhat.io
                mon-ip: node1
                orphan-initial-daemons: true
          - config:
              command: add_hosts
              service: host
              args:
                attach_ip_address: true
                labels: apply-all-labels
          - config:
              command: apply
              service: mgr
              args:
                placement:
                  label: mgr
          - config:
              command: apply
              service: mon
              args:
                placement:
                  label: mon
          - config:
              command: apply
              service: osd
              args:
                all-available-devices: true
          - config:
              command: shell
              args: # arguments to ceph orch
                - ceph
                - fs
                - volume
                - create
                - cephfs
          - config:
              command: apply
              service: rgw
              pos_args:
                - rgw.1
              args:
                placement:
                  label: rgw
          - config:
              command: apply
              service: mds
              base_cmd_args: # arguments to ceph orch
                verbose: true
              pos_args:
                - cephfs # name of the filesystem
              args:
                placement:
                  nodes:
                    - node2
                    - node6
                  limit: 2 # no of daemons
                  sep: " " # separator to be used for placements
      destroy-cluster: false
      abort-on-fail: true

  - test:
      name: Configure client admin
      desc: Configures client admin node on cluster
      module: test_client.py
      abort-on-fail: true
      polarion-id:
      config:
        command: add
        id: client.1 # client Id (<type>.<Id>)
        node: node7
        install_packages:
          - ceph-common
        copy_admin_keyring: true # Copy admin keyring to node
        caps: # authorize client capabilities
          mon: "allow *"
          osd: "allow *"
          mds: "allow *"
          mgr: "allow *"

  - test:
      name: Enable logging to file
      module: rados_prep.py
      config:
        log_to_file: true
      desc: Change config options to enable logging to file

  - test:
      name: Bluestore data compression - enable write v2 and validate
      module: test_bluestore_comp_enhancements.py
      desc: Positive workflows for bluestore data compression enhancements
      polarion-id: CEPH-83620071
      config:
        delete_pool: True
        scenarios_to_run:
          - scenario-1
          - scenario-2
          - scenario-3

  - test:
      name: Bluestore data compression - basic workflow - write v2
      module: test_bluestore_data_compression.py
      desc: Positive workflows for bluestore data compression
      polarion-id: CEPH-83611889
      config:
        compression_algorithm: "zlib"
        delete_pool: True
        scenarios_to_run:
          - scenario-1

  - test:
      name: Bluestore data compression - uncompressed pool to compressed pool conversion - write v2
      module: test_bluestore_data_compression.py
      desc: Positive workflows for bluestore data compression
      polarion-id: CEPH-83611889
      config:
        compression_algorithm: "snappy"
        delete_pool: True
        scenarios_to_run:
          - scenario-2

  - test:
      name: Bluestore data compression - compressed pool to uncompressed pool conversion - write v2
      module: test_bluestore_data_compression.py
      desc: Positive workflows for bluestore data compression
      polarion-id: CEPH-83611889
      config:
        compression_algorithm: "zlib"
        delete_pool: True
        scenarios_to_run:
          - scenario-3

  - test:
      name: Bluestore data compression - osd level compression - write v2
      module: test_bluestore_data_compression.py
      desc: Positive workflows for bluestore data compression
      polarion-id: CEPH-83611889
      config:
        compression_algorithm: "snappy"
        delete_pool: True
        scenarios_to_run:
          - scenario-4

  - test:
      name: Bluestore data compression - pools inherit compression configurations from OSD - write v2
      module: test_bluestore_data_compression.py
      desc: Positive workflows for bluestore data compression
      polarion-id: CEPH-83611889
      config:
        compression_algorithm: "zlib"
        scenarios_to_run:
          - scenario-5

  - test:
      name: Bluestore data compression - Validate data migration between compressed pools - write v2
      module: test_bluestore_data_compression.py
      desc: Positive workflows for bluestore data compression
      polarion-id: CEPH-83611889
      config:
        compression_algorithm: "snappy"
        scenarios_to_run:
          - scenario-6

  - test:
      name: Bluestore data compression - Validate OSD replacement - write v2
      module: test_bluestore_data_compression.py
      desc: Positive workflows for bluestore data compression
      polarion-id: CEPH-83611889
      config:
        compression_algorithm: "zlib"
        scenarios_to_run:
          - scenario-7

  # Commenting test case due to BZ :- https://bugzilla.redhat.com/show_bug.cgi?id=2412464
  #  - test:
  #        name: Bluestore data recompression - overwrite tests - pool level compression tests
  #        module: test_bluestore_comp_enhancements.py
  #        desc: Positive workflows for bluestore data compression enhancements
  #        polarion-id: CEPH-83620071
  #        abort-on-fail: true
  #        config:
  #          pool_level_compression: True
  #          scenarios_to_run:
  #            - scenario-4
  #          recompression_min_gain_to_test:
  #            - 0.9
  #            - 1.2
  #            - 1.5
  #          object_sizes_to_test:
  #            - 750000
  #            - 92000

  - test:
      name: Bluestore data recompression - min alloc size tests 1 - write v2
      module: test_bluestore_comp_enhancements.py
      desc: Positive workflows for bluestore data compression enhancements
      polarion-id: CEPH-83620071
      config:
        compression_algorithm: "snappy"
        pool_level_compression: True
        scenarios_to_run:
          - scenario-5
        min_alloc_size_to_test:
          - 4096
        min_alloc_size_variations:
          - 2000
          - -2000

  - test:
      name: Bluestore data recompression - min alloc size tests 2 - write v2
      module: test_bluestore_comp_enhancements.py
      desc: Positive workflows for bluestore data compression enhancements
      polarion-id: CEPH-83620071
      config:
        compression_algorithm: "zlib"
        pool_level_compression: True
        scenarios_to_run:
          - scenario-5
        min_alloc_size_to_test:
          - 8192
        min_alloc_size_variations:
          - 4000
          - -4000

  - test:
      name: Bluestore target blob size variation test - write v2
      module: test_bluestore_comp_enhancements.py
      desc: Positive workflows for bluestore data compression enhancements
      polarion-id: CEPH-83620071
      config:
        compression_algorithm: "snappy"
        scenarios_to_run:
          - scenario-6

  - test:
      name: Bluestore blob size tests - write v2
      module: test_bluestore_comp_enhancements.py
      desc: Positive workflows for bluestore data compression enhancements
      polarion-id: CEPH-83620071
      config:
        compression_algorithm: "zlib"
        scenarios_to_run:
          - scenario-7

  - test:
      name: Bluestore OSD down during IO scenario - write v2
      module: test_bluestore_comp_enhancements.py
      desc: Positive workflows for bluestore data compression enhancements
      polarion-id: CEPH-83620071
      config:
        compression_algorithm: "snappy"
        scenarios_to_run:
          - scenario-9

  - test:
      name: Bluestore OSD host down during IO scenario - write v2
      module: test_bluestore_comp_enhancements.py
      desc: Positive workflows for bluestore data compression enhancements
      polarion-id: CEPH-83620071
      config:
        compression_algorithm: "zlib"
        scenarios_to_run:
          - scenario-10

  - test:
      name: Bluestore compression validation post OSD restart - write v2
      module: test_bluestore_comp_enhancements.py
      desc: Positive workflows for bluestore data compression enhancements
      polarion-id: CEPH-83620071
      config:
        compression_algorithm: "zstd"
        scenarios_to_run:
          - scenario-11

  - test:
      name: Bluestore compression - data integrity test - write v2
      module: test_bluestore_comp_enhancements.py
      desc: Positive workflows for bluestore data compression enhancements
      polarion-id: CEPH-83620071
      config:
        compression_algorithm: "lz4"
        scenarios_to_run:
          - scenario-12

  - test:
      name: Bluestore disable bluestore_write_v2 and validate
      module: test_bluestore_comp_enhancements.py
      desc: Positive workflows for bluestore data compression enhancements
      polarion-id: CEPH-83620071
      config:
        scenarios_to_run:
          - scenario-8
