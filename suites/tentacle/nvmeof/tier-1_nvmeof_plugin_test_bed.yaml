#===============================================================================================
# Tier-level: 1
# Test-Suite: tier-1_nvmeof_plugin_test_bed.yaml
# Test-Case: Deploy Ceph cluster, 2 NVMe gateway groups, and configure subsystems and listeners only
# Polarion ID : CEPH-XXXXX
#
# Cluster Configuration:
#    Conf file - conf/squid/nvmeof/ceph_nvmeof_sanity.yaml (or similar)
#    No of Clusters : 1
#
# The following evaluations are carried out
#   (1) Deploys Ceph cluster using cephadm
#   (2) Configures client
#   (3) Deploys 2 NVMe gateway groups (gw_group1 on nodes with label nvmeof-gw, gw_group2 on nodes with label nvmeof-gw-2)
#   (4) Configures 3 subsystems per gateway group
#   (5) Configures listeners for each subsystem on the gateway nodes
#   (6) Does NOT configure hosts or namespaces (by omitting allow_host, hosts, and bdevs from config)
#   (7) Does NOT perform cleanup (cleanup not specified in config)
#===============================================================================================
tests:
  - test:
      abort-on-fail: true
      module: install_prereq.py
      name: install ceph pre-requisites
  - test:
      abort-on-fail: true
      config:
        verify_cluster_health: true
        steps:
          - config:
              command: bootstrap
              service: cephadm
              args:
                mon-ip: node1
                registry-url: registry.redhat.io
                allow-fqdn-hostname: true
                log-to-file: true
          - config:
              command: add_hosts
              service: host
              args:
                attach_ip_address: true
                labels: apply-all-labels
          - config:
              command: apply
              service: mgr
              args:
                placement:
                  label: mgr
          - config:
              command: apply
              service: mon
              args:
                placement:
                  label: mon
          - config:
              command: apply
              service: osd
              args:
                all-available-devices: true
      desc: RHCS cluster deployment using cephadm
      destroy-cluster: false
      module: test_cephadm.py
      name: deploy cluster

  - test:
      abort-on-fail: true
      config:
        command: add
        id: client.1
        nodes:
          - node10
        install_packages:
          - ceph-common
        copy_admin_keyring: true
      desc: Setup client for NVMe tests
      destroy-cluster: false
      module: test_client.py
      name: configure Ceph client

  # Deploy first NVMe gateway group on nodes with label nvmeof-gw
  - test:
      abort-on-fail: true
      config:
        verify_cluster_health: true
        steps:
          - config:
              command: shell
              args:
                - ceph osd pool create rbd
          - config:
              command: shell
              args:
                - ceph osd pool application enable rbd rbd
          - config:
              command: apply
              service: nvmeof
              args:
                placement:
                  label: nvmeof-gw
              pos_args:
                - rbd
                - gw_group1
      desc: NVMeoF Gateway group 1 deployment using cephadm
      destroy-cluster: false
      module: test_cephadm.py
      name: deploy nvmeof gateway group 1

  # Deploy second NVMe gateway group on nodes with label nvmeof-gw-2
  - test:
      abort-on-fail: true
      config:
        verify_cluster_health: true
        steps:
          - config:
              command: apply
              service: nvmeof
              args:
                placement:
                  label: nvmeof-gw-2
              pos_args:
                - rbd
                - gw_group2
      desc: NVMeoF Gateway group 2 deployment using cephadm
      destroy-cluster: false
      module: test_cephadm.py
      name: deploy nvmeof gateway group 2

  # Configure first gateway group (gw_group1) with 3 subsystems
  - test:
      abort-on-fail: true
      config:
        gw_nodes:
          - node4
          - node5
        rbd_pool: rbd
        nvme_metadata_pool: rbd
        gw_group: gw_group1
        do_not_create_image: true
        rep-pool-only: true
        rep_pool_config:
          pool: rbd
        install: false  # Already deployed via cephadm
        subsystems:
          - nqn: nqn.2016-06.io.spdk:cnode1
            serial: 1
            listener_port: 4420
            listeners:
              - node4
              - node5
          - nqn: nqn.2016-06.io.spdk:cnode2
            serial: 2
            listener_port: 4420
            listeners:
              - node4
              - node5
          - nqn: nqn.2016-06.io.spdk:cnode3
            serial: 3
            listener_port: 4420
            listeners:
              - node4
              - node5
            # Note: allow_host, hosts, and bdevs are intentionally omitted
            # to skip host and namespace configuration
      desc: Configure gateway group 1 with 3 subsystems and listeners (no hosts, no namespaces, no cleanup)
      destroy-cluster: false
      module: test_ceph_nvmeof_gateway.py
      name: Configure NVMe gateway group 1
      polarion-id: CEPH-XXXXX

  # Configure second gateway group (gw_group2) with 3 subsystems
  - test:
      abort-on-fail: true
      config:
        gw_nodes:
          - node6
          - node7
        rbd_pool: rbd
        nvme_metadata_pool: rbd
        gw_group: gw_group2
        do_not_create_image: true
        rep-pool-only: true
        rep_pool_config:
          pool: rbd
        install: false  # Already deployed via cephadm
        subsystems:
          - nqn: nqn.2016-06.io.spdk:cnode4
            serial: 4
            listener_port: 4420
            listeners:
              - node6
              - node7
          - nqn: nqn.2016-06.io.spdk:cnode5
            serial: 5
            listener_port: 4420
            listeners:
              - node6
              - node7
          - nqn: nqn.2016-06.io.spdk:cnode6
            serial: 6
            listener_port: 4420
            listeners:
              - node6
              - node7
            # Note: allow_host, hosts, and bdevs are intentionally omitted
            # to skip host and namespace configuration
      desc: Configure gateway group 2 with 3 subsystems and listeners (no hosts, no namespaces, no cleanup)
      destroy-cluster: false
      module: test_ceph_nvmeof_gateway.py
      name: Configure NVMe gateway group 2
      polarion-id: CEPH-XXXXX
